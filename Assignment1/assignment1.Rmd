---
title: "Assignment1"
author: "Shah Ali"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list=ls())
library(tidyverse)
library(estimatr)
library(modelsummary)
library(dplyr)
library(data.table)
library(fixest)
library(caret)
library(gridExtra)
library(kableExtra)
library(ggpubr)
```


```{r,echo=FALSE}
###########################################
## Set data dir, load theme and functions##
###########################################

# Importing the data
data <- fread("https://osf.io/4ay9x/download")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
################
# Data Munging #
################

# Number of Observation in each Occupation 
ob <- data[,.(Count=.N),by=occ2012]
ob2 <- data %>% filter(occ2012==5240)

# Filtering the data for the chosen occupation (Customer service representative)
dt <- data %>% filter(occ2012==5240)
dt <-  data.table(dt)

datasummary_skim(dt)

# Creating a new wage per hour variable w
dt <- dt[, w := earnwke/uhours]
dt <- dt[age >= 20]

# Filtering on uhours to work on full time employee (minimum 40 hours) (dropped obs = 620 obs)
dt <- dt[uhours >= 40]

# counting Number observation in each Education Level
# Filter: keeping bachelors and under (dropped 109 observation)
dt[,.(count=.N), by= grade92]
dt <- dt[grade92 <= 43 & grade92 >= 39]  

# Checking age greater than 20
dt[,.(count=.N), by= age]
dt <- dt[age >= 20] #14 obs gone

# Looking at a quick summary of some of the key variables
datasummary(w + grade92 + age ~ Mean + SD + Min + Max + P25 + P75 + N , data = dt)

# Finding missing values
to_filter <- sapply(dt, function(x) sum(is.na(x)))
to_filter[to_filter > 0]

# dropping the ethnic column since there are 919 NA observation in the column 
dt <- dt[, ethnic := NULL]
```

```{r message=FALSE, warning=FALSE, include=FALSE}

# Creating levels for grade92 variable in a new variable educ#
dt <- dt[grade92 == 43, educ := "Bachelors"]
dt <-dt[grade92 == 42, educ := "Associate Degree academic program"]
dt <-dt[grade92 == 41, educ := "Associate Degree occupational program"]
dt <-dt[grade92 == 40, educ := "College"]
dt <-dt[grade92 == 39, educ := "High School"]
dt <- dt[, grade92 := NULL]

datasummary( w*factor(educ) ~ N + SD +Percent() + Mean, data = dt )

# Creating age squared column
dt <- dt[, agesq := age^2]

# checking result
datasummary(w*factor(educ) + age ~ Mean + SD + Min + Max + P25 + P75 + N , data = dt)

# creating binary for white and non white
dt$white <- ifelse(dt$race==1,1,0)
dt <- dt %>%
  select(-c(race))

# Creating factor sex variable
dt <- dt[sex == 1, gender := "male"]
dt <- dt[sex == 2, gender := "female"]
dt <- dt %>%
  select(-c(sex))

# Creating factor variable for marital variable
dt[marital <= 2, married_status := "married"]
dt[marital <= 6 & marital >= 3, married_status := "separated"]
dt[marital == 7, married_status := "never married"]
dt <- dt %>%
  select(-c(marital))

# Ownchild
dt[,.(count=.N), by= ownchild]

# Create if individuals own child or no
dt <- dt %>% mutate(ownchild=case_when(
  ownchild==0 ~ 0,
  TRUE ~ 1))
datasummary( w*factor(ownchild) ~ N + SD + Mean, data = dt ) 

# dropping chldpres because our ownchild is same
dt <- dt %>%
  select(-chldpres)

# dropping industries 
datasummary( w*(ind02) ~ N + Percent() + Mean, data = dt )
dt <- dt %>% select(-ind02)

# class
datasummary( w*factor(class) ~ N + Percent() + Mean, data = dt ) 

# Including Class as factor
dt <- dt[class == "Government - Federal"| class=="Government - Local"|class=="Government - State", Sector := "Government"]
dt <- dt[class == "Private, For Profit"| class=="Private, Nonprofit", Sector := "Private"]
datasummary( w*factor(Sector) ~ N + Percent() + Mean, data = dt ) 
dt <- dt %>% select(-class)

# unionmme
datasummary( w*factor(unionmme) ~ N + Percent() + Mean, data = dt ) 

# state 
datasummary( w*factor(state) ~ N + Percent() + Mean, data = dt ) 

# lfsr94(mean difference is minor between these two so excluding from)
datasummary( w*factor(lfsr94) ~ N + Percent() + Mean, data = dt ) 
# exclude from model
dt <- dt %>% select(-lfsr94)

# prcitshp grouping in to Foregin and Native
datasummary( w*factor(prcitshp) ~ N + Percent() + Mean, data = dt ) 
dt <- dt[prcitshp=="Native, Born Abroad Of US Parent(s)"|prcitshp=="Native, Born in PR or US Outlying Area"|prcitshp=="Native, Born In US",origin := "Native"]
dt <- dt[prcitshp=="Foreign Born, Not a US Citizen"|prcitshp=="Foreign Born, US Cit By Naturalization",origin := "Foreign "]
dt <- dt %>% select(-prcitshp)
datasummary( w*factor(origin) ~ N + Percent() + Mean, data = dt ) 

##Creating region based on states, Used Aftabs ideas to group these codes in region 
dt <- dt[stfips %in% c("WA", "OR", "MT", "ID", "WY", "NV", "UT", "CO", "AZ", "NM", "HI", "AK", "CA"), region := "other"]
dt <- dt[stfips %in% c("ND", "SD", "NE", "KS", "MN", "IA", "MO", "WI", "IL", "IN", "MI", "OH"), region := "other"]
dt <- dt[stfips %in% c("OK", "TX", "AR", "LA", "KY", "TN", "MS", "AL", "WV", "VA", "NC", "SC", "GA", "FL", "DC","MD","DE"), region := "other"]
dt <- dt[stfips %in% c("PA", "NY", "VT", "NH", "ME","MA","RI","CT","NJ"), region := "north-east"]
datasummary( w*factor(region) ~ N + Percent() + Mean, data = dt )

# excluding unwanted variable
dt <- dt %>% select(-c(V1,hhid,intmonth,weight,occ2012,stfips,state))

```


```{r , echo= F ,message=FALSE, warning=FALSE, include=FALSE}

###################################
## Setting up Regressions models ##
###################################


#1#
# datasummary( w*factor(white)*gender ~ N + Percent() + Mean, data = dt ) 


#Boxplot#
white_gender <- ggplot(dt, aes(x = factor(white), y = w,
                              fill = factor(gender), color=factor(gender))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Race",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=90, vjust=.5))


#2#
datasummary( w*factor(educ)*gender ~ N + Percent() + Mean, data = dt )
# wage is very different based on education and gender
## Boxplot##
educ_gender <- ggplot(dt, aes(x = factor(educ), y = w,
                              fill = factor(gender), color=factor(gender))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Education",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))


#3#
datasummary( w*married_status*gender ~ N + Percent() + Mean, data = dt )#3
# wage is very different based on , married_status and gender
## Boxplot##

Mstatus_gender <- ggplot(dt, aes(x = factor(married_status), y = w,
                              fill = factor(gender), color=factor(gender))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Married status",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))


#4#
datasummary( w*Sector*gender ~ N + Percent() + Mean, data = dt )#4
# wage is very different based on education and gender

## Boxplot##
Sector_gender <- ggplot(dt, aes(x = factor(Sector), y = w,
                              fill = factor(gender), color=factor(gender))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Sector",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))


#5#
datasummary( w*unionmme*gender ~ N + Percent() + Mean, data = dt )

## Boxplot##
Union_gender <- ggplot(dt, aes(x = factor(unionmme), y = w,
                              fill = factor(gender), color=factor(gender))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Union Membership",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))


```

```{r message=FALSE, warning=FALSE, include=FALSE}
#6#
datasummary( w*unionmme*Sector ~ N + Percent() + Mean, data = dt )#3
## Boxplot##
Union_Sector <- ggplot(dt, aes(x = factor(unionmme), y = w,
                              fill = factor(Sector), color=factor(Sector))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Union Membership",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))


#7#
datasummary( w*origin*Sector ~ N + Percent() + Mean, data = dt ) # not including since the wage differential is low


#8#
datasummary(w*Sector*region ~ N + Percent() + Mean, data = dt)
## Boxplot##
Sector_Region<- ggplot(dt, aes(x = factor(region), y = w,
                              fill = factor(Sector), color=factor(Sector))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Region",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))

#9#
datasummary(w*factor(white)*factor(married_status)  ~ N + Percent() + Mean, data = dt )
#not much difference - can ignore this

## Boxplot##
White_Status<- ggplot(dt, aes(x = factor(married_status), y = w,
                              fill = factor(white), color=factor(white))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Marriage Status",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))

#10# # small wage difference Not including 
datasummary(w*factor(ownchild)*factor(gender) ~ N + Percent() + Mean, data = dt)


#11#
datasummary(w*origin*factor(educ)  ~ N + Percent() + Mean, data = dt) 
# big differences observed 

origin_educ <- ggplot(dt, aes(x = factor(educ), y = w,
                              fill = factor(origin), color=factor(origin))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c('red','blue')) +
  scale_fill_manual(name="",
                    values=c('red','blue')) +
  labs(x = "Education",y = "Wage per Hour (USD)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 70), breaks = seq(0,70, 10))+
  ggthemes::theme_economist() +
  theme(legend.position = c(0.15,0.85), axis.text.x = element_text(angle=45, vjust=.5))

#12#
# (Will be keeping this for final model. Bifurcated the regions into 2 North-East and Other for simiplicity. Too Varibales too many can lead to over fitting as well as penality)
datasummary(w*factor(educ)*region  ~ N + Percent() + Mean, data = dt )

```

```{r message=FALSE, warning=FALSE, include=FALSE}

###################################
## Setting up Regressions models ##
###################################

model1 <- as.formula(w ~ educ)

model2 <- as.formula(w ~ educ+age+agesq+white)

model3 <- as.formula(w ~ educ+age+agesq+white+educ*gender+factor(married_status)*gender+ Sector*gender+factor(origin)*factor(region)+factor(origin)*educ)

model4 <- as.formula(w ~ educ+age+agesq+white+educ*gender+factor(married_status)*gender+ Sector*gender+factor(origin)*factor(region)+factor(origin)*educ + factor(unionmme)*gender+
unionmme*Sector+Sector*factor(region)+white*factor(married_status))

### Running the regressions
reg1 <- feols(model1, data = dt , vcov="hetero")
reg2 <- feols(model2, data = dt , vcov="hetero")
reg3 <- feols(model3, data = dt , vcov="hetero")
reg4 <- feols(model4, data = dt , vcov="hetero")

 # evaluation of the models: using all the sample#
fitstat_register("k", function(x){length( x$coefficients ) - 1}, "No. Variables")           
etable <- etable( reg1 , reg2 , reg3 , reg4 , fitstat = c('aic','bic','rmse','r2','n','k'), keepFactors = TRUE )

reg_results <- etable( reg1 , reg2 , reg3 , reg4 , fitstat = c('aic','bic','rmse','r2','n','k'), keepFactors = TRUE )

reg_stats <- setDF(reg_results)

models <- c("Model 1", "Model 2", "Model 3", "Model 4")
rmse <- c(reg_stats$reg1[39], reg_stats$reg2[39], reg_stats$reg3[39] ,reg_stats$reg4[39])
bic <- c(reg_stats$reg1[38], reg_stats$reg2[38], reg_stats$reg3[38] ,reg_stats$reg4[38])
vars <- c(reg_stats$reg1[42], reg_stats$reg2[42], reg_stats$reg3[42] ,reg_stats$reg4[42])
reg_stats$reg1
reg_results_table <- data.frame(models, bic, rmse, vars)

colnames(reg_results_table)<- c("Model", "BIC", "RMSE","No. of coeff")

reg_results_table <- reg_results_table %>% mutate_if(is.numeric, format) %>%
  kable( caption = "Model evaluation based on full sample RMSE and BIC") %>%
  kable_styling(full_width = F, font_size = 10)







#####################
# Cross-validation for better evaluation of predictive performance
# Simple k-fold cross validation setup:
# 1) Used method for estimating the model: "lm" - linear model (y_hat = b0+b1*x1+b2*x2 + ...)
# 2) set number of folds to use (must be less than the no. observations)
k <- 4
# We use the 'train' function which allows many type of model training -> use cross-validation
set.seed(150)
cv1 <- train(model1, dt, method = "lm", trControl = trainControl(method = "cv", number = k))
# Check the output:
cv1
summary(cv1)
cv1$results
cv1$resample
set.seed(150)
cv2 <- train(model2, dt, method = "lm", trControl = trainControl(method = "cv", number = k))
set.seed(150)
cv3 <- train(model3, dt, method = "lm", trControl = trainControl(method = "cv", number = k), na.action = "na.omit")
set.seed(150)
cv4 <- train(model4, dt, method = "lm", trControl = trainControl(method = "cv", number = k), na.action = "na.omit")
# Calculate RMSE for each fold and the average RMSE as well
cv <- c("cv1", "cv2", "cv3", "cv4")
rmse_cv <- c()
for(i in 1:length(cv)){
  rmse_cv[i] <- sqrt((get(cv[i])$resample[[1]][1]^2 +
                        get(cv[i])$resample[[1]][2]^2 +
                        get(cv[i])$resample[[1]][3]^2 +
                        get(cv[i])$resample[[1]][4]^2)/4)
}
# summarize results
cv_mat <- data.frame(rbind(cv1$resample[4], "Average"),
                     rbind(cv1$resample[1], rmse_cv[1]),
                     rbind(cv2$resample[1], rmse_cv[2]),
                     rbind(cv3$resample[1], rmse_cv[3]),
                     rbind(cv4$resample[1], rmse_cv[4])
)
colnames(cv_mat)<-c("Resample","Model1", "Model2", "Model3", "Model4")
cv_mat 
# Show model complexity and out-of-sample RMSE performance
m_comp <- c()
models <- c("reg1", "reg2", "reg3", "reg4")
for( i in 1 : length(cv) ){
  m_comp[ i ] <- length( get( models[i] )$coefficient  - 1 ) 
}
m_comp <- tibble( model = models , 
                  complexity = m_comp,
                  RMSE = rmse_cv )
kfold <- ggplot( m_comp , aes( x = complexity , y = RMSE ) ) +
  geom_point(color='red',size=2) +
  geom_line(color='blue',size=0.5)+
  labs(x='Number of explanatory variables',y='Averaged RMSE on test samples',
       title='Prediction performance and model compexity') +
  ggthemes::theme_economist()
# plotting results
line <- ggplot(dt, aes(x=predict(reg2, dt), y=w)) + 
  geom_point(alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, size = 0.5) +
  scale_x_continuous(limits = c(0,30)) + 
  scale_y_continuous(limits = c(0,60)) +
  ggthemes::theme_economist()

```

## Introduction ##

The aim of this assignment is to build 4 predictive models using linear regression on the provided data set and then critically comparing and analyzing each of them on the basis of RMSE, cross-validated RMSE and BIC of the sample. The data set used for the analysis is [*cps-earnings*](https://osf.io/g8p9j/)* and the target variable of interest _*earnings per hour (w)*_. The choice of occupation for the analysis which is  _*Customer service representative*_ is based on high number of observations available to start with (2329 observations) and also because of my background in this field

## Data Cleaning & Munging ##

For this analysis, only full-time employees are chosen (those working 40 hours or more) and the education level up to Bachelors degree is selected since this job role does not require higher education. The ethnicity variable was excluded as it contained close to 50% missing values and data contained race variable to cater to our needs. For the variables such as married status, gender, class, race, state ,citizenship status, new categorical variables are created by grouping within each since not variation was seen in them and to reduce the complexity during analysis.

## Predictor variables and Interaction terms ##

After data cleaning, we were left were the required predictors which are to be used for creating the interaction terms. About 12 different interaction terms were created, each evaluated to see its effect on on _*earnings per hour (w)*_. Criteria for choosing the interaction term for the models rested on the fact if the mean of the change in *w* is significant, that is USD 2 or beyond and number of observations is comparable, that is within 33% of each other. Based on this criteria, 3 interaction terms were not included in the any of prediction models, those with the change in mean of *w* greater than USD 3 were included in Model 3 and Model 4 included all fulfilling the criteria.

## Regression Model ##

After running the predictive models we are now tasked with comparing these models based on: *_1) RMSE in the full sample*_ _*2) Cross-validated RMSE*_ _*3) BIC in the full sample*_ 
The regression table shows that Model 4 which is the most complex model with 13 predictor terms has the lowest full sample RMSE of 8.87, while the full sample RMSE of Model 3 (with 10 predictors) is 8.92. This is a negligible difference, and with higher BIC value for Model 4 suggests overfitting and is subjected to penalty of adding more predictor terms. The cross-validated RMSE for both Model 3 and Model 4 is same (9.06 and 9.05 respectively) and when comparing these with simpler model, Model 2 we see that its value is 9.2. There is a very minor, hence we prefer Model 2 while comparing full sample and K-fold RMSEs as it is simpler and less complex. Lastly, we now check the full sample BIC of the models. Of all models, the lowest BIC is for Model 2 (11565) which  further validates that our choice of Model 2 as best and less complex.
To sum up, while it true that lowest RMSEs value are in Model 4, the difference between those of Model 2 is very minute. We choose the *Model 2* as it is a simple model that help us to avoid over fitting the live data and easier to work with.


## Appendix ##

## Interactions Boxplot

```{r,echo=F,warning=F,fig.width=8,fig.height=10,fig.align="center"}
ggarrange(educ_gender,Mstatus_gender,origin_educ,Sector_gender,hjust=-0.6,ncol=2,nrow=2)
```
\newpage
```{r,echo=F,warning=F,fig.width=8,fig.height=10,fig.align="center"}
ggarrange(Sector_Region,Union_gender,Union_Sector,White_Status,white_gender,hjust=-0.6,ncol=2,nrow=3)
```


```{r,echo=FALSE, message=FALSE, warning=FALSE,fig.align='left', show.fig = 'hold'}
 cv_mat %>% kbl(caption = "Cross Validated RMSE", booktabs = T) %>%
  kable_paper("striped", full_width = T) %>%
  row_spec(5, bold = T)


```

## Model of Best-Fit ~ Model 2
```{r,echo=FALSE, message=FALSE, warning=FALSE,fig.align='left', show.fig = 'hold'}
line
kfold
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
reg_results_table
```

\newpage

```{r,echo=FALSE, message=FALSE, warning=FALSE,fig.align='left', show.fig = 'hold'}

etable %>% kbl(caption = "Regression Table", booktabs = T) %>%
  kable_styling(latex_options = c("striped","scale",full_width = T))


```
