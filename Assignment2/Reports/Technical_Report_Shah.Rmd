---
title: "Technical Report"
author: "Shah Ali"
date: "2/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}


# ------------------------------------------------------------------------------------------------------
#### SET UP
# It is advised to start a new session for every case study
# CLEAR MEMORY
rm(list=ls())


# Descriptive statistics and regressions
library(tidyverse)
library(caret)
library(skimr)
library(grid)
library(glmnet)
library(stargazer)
library(xtable)
library(directlabels)
library(knitr)
library(cowplot)
library(rattle)
library(ranger)
library(Hmisc)
library(kableExtra)
library(ggcorrplot)
library(rpart)
library(rpart.plot)
library(ggpubr)


# set data dir, load theme and functions
path <- "/Users/shahali/Documents/winter_semester/DA3/Assignments/Assignment2/"

source(paste0(path, "da_helper_function.R"))
source(paste0(path, "theme_bg.R"))

# data used
data_in <- paste0(path,"Data/Clean/")
data_out <- paste0(path,"Data/Clean/")
output <- paste0(path,"Output/")


options(digits = 3)

##############################################################################################
# PART I.
##############################################################################################


#############
# Load data #
#############

data <-
  read_csv(paste0(data_in, "puglia_workfile_adj.csv")) %>%
  mutate_if(is.character, factor)


```

```{r message=FALSE, warning=FALSE, include=FALSE}
######################
# Quick look at data #
######################
glimpse(data)

# where do we have missing variables now? => NO!
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]


#####################
### looking at price ###
#####################


#dealing with price
summary(data$price)
describe(data$price)



data$price  <- as.numeric(data$price)

data %>% filter(price >= 500) %>% 
  summarise(cnt = n()) %>%
  arrange(-cnt)

#dropping EV values
data <-   data %>% filter(price <= 500)

# with price info only
data<- data %>%
  drop_na(price)

# Price Distribution

price_hist <- ggplot(data, aes( x = price)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)),fill = "cyan3", color = "black") +
  theme_bw() +
  scale_y_continuous(labels = label_percent()) +
  ylab("Percent") +
  xlab("Price (Euros)")
price_hist

ln_price_hist <- ggplot(data, aes(x = log(price))) +
  geom_histogram(aes(y = (..count..)/sum(..count..)),fill = "cyan3", color = "black") +
  theme_bw() +
  scale_y_continuous(labels = label_percent()) +
  ylab("Percent") +
  xlab("ln(Price, Euros)")
ln_price_hist

price_hist_grid <- ggarrange(
  price_hist,
  ln_price_hist,
  nrow = 1)


annotate_figure(price_hist_grid,bottom =
                  text_grob("Note: Apartments with 2-6 accommodation capacity. Histogram without extreme values (price < 500 Euros)"))



#####################################
# Look at some descriptive statistics
#####################################

#How is the average price changing  by `property_type`,?
data %>%
  group_by(property_type) %>%
  summarise(count=n())
# dplyr::summarize(mean_price = mean(price, na.rm=TRUE)) %>%
# summarise(count=n())


price_vs_property_box <- ggplot(data = data, aes(x = property_type, y = price)) +
  stat_boxplot(aes(group = property_type), geom = "errorbar", width = 0.3,
               color = c(color[2],color[1],color[3],color[4]), size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = property_type),
               color = c(color[2],color[1],color[3],color[4]), fill = c(color[2],color[1],color[3],color[4]),
               size = 0.5, width = 0.6, alpha = 0.3, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,550), breaks = seq(0,550,50)) +
  labs(x = "Property type",y = "Price (Euros)")+
  geom_point(alpha = 0.5, size =0.5)+
  theme_bg()
price_vs_property_box


describe(data$price)
# Barchart  
fig4 <- ggplot(data = data, aes(x = factor(n_accommodates), color = f_property_type, fill = f_property_type)) +
  geom_bar(alpha=0.6, na.rm=T, width = 0.8) +
  scale_color_manual(name="",
                     values=c(color[2],color[1],color[3],color[4])) +
  scale_fill_manual(name="",
                    values=c(color[2],color[1],color[3],color[4])) +
  labs(x = "Accomodates (Persons)",y = "Frequency")+
  theme_classic()
fig4

viz2 <- ggarrange(
  price_vs_property_box,
  fig4,
  nrow = 1)

```


```{r message=FALSE, warning=FALSE, include=FALSE}
#######################################
# PART II.
########################################



#####################
# Setting up models #
#####################

# Basic Variables
basic_lev  <- c("f_property_type", "n_accommodates", "n_beds",  "n_days_sincelast", "flag_days_sincelast")

# Factorized variables
basic_add <- c("f_bathroom", "f_bedroom", "f_neighbourhood_group_cleansed", "f_minimum_nights", "n_availability_365")

reviews <- c("n_review_scores_rating", "flag_review_scores_rating","f_review_scores_rating",
             "n_number_of_reviews","f_number_of_reviews","n_reviews_per_month","flag_reviews_per_month")

host <- c("d_host_is_superhost", "d_host_identity_verified")

# Dummy variables: Extras -> collect all options and create dummies
dummies <-  grep("^d_.*", names(data), value = TRUE)        


# Define models: simpler, extended -----------------------------------------------------------

#################################
# Look for interactions         #
#################################

## This huge correlation table shows how strongly numeric variables are correlated
num_data <- data[,unlist(lapply(data, is.numeric))]  
num_data <- num_data %>%  select(matches("^d_.*|^n_.*|^f_.*|^p.*"))

corr <- round(cor(num_data), 1)
ggcorrplot(corr)


price_diff_by_variables4 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){
  # Looking for interactions.
  # It is a function it takes 3 arguments: 1) Your dataframe,
  # 2) the factor variable (like room_type)
  # 3)the dummy variable you are interested in (like TV)
  
  # Process your data frame and make a new dataframe which contains the stats
  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)
  
  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(Mean = mean(price, na.rm=TRUE),
                     se = sd(price)/sqrt(n()))
  
  stats[,2] <- lapply(stats[,2], factor)
  
  ggplot(stats, aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2]))+
    geom_bar(stat='identity', position = position_dodge(width=0.9), alpha=0.8)+
    geom_errorbar(aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
                  position=position_dodge(width = 0.9), width = 0.25)+
    scale_color_manual(name=dummy_lab,
                       values=c(color[2],color[1],color[3],color[4])) +
    scale_fill_manual(name=dummy_lab,
                      values=c(color[2],color[1],color[3],color[4])) +
    ylab('Mean Price')+
    xlab(factor_lab) +
    theme_bg()+
    theme(panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),
          panel.border=element_blank(),
          axis.line=element_line(),
          legend.position = "top",
          #legend.position = c(0.7, 0.9),
          legend.box = "vertical",
          legend.text = element_text(size = 5),
          legend.title = element_text(size = 5, face = "bold"),
          legend.key.size = unit(x = 0.4, units = "cm")
    )
}



# Plot interactions between room type/property type and all dummies
sapply(dummies, function(x){
  p <- price_diff_by_variables4(data, "f_property_type", x, "property_type", x)
  print(p)
})


interactions <- c("f_property_type*d_barbecue_utensils",
"f_property_type*d_bed_linens",
"f_property_type*d_bikes",
"f_property_type*d_cleaning_before_checkout",
"f_property_type*d_cleaning_products",
"f_property_type*d_cooking_basics",
"f_property_type*d_dishes_and_silverware",
"f_property_type*d_essentials",
"f_property_type*d_ethernet_connection",
"f_property_type*d_ev_charger",
"f_property_type*d_extra_pillows_and_blankets",
"f_property_type*d_fire_pit",
"f_property_type*d_freezer",
"f_property_type*d_hangers",
"f_property_type*d_hot_tub",
"f_property_type*d_hot_water",
"f_property_type*d_lockbox",
"f_property_type*d_long_term_stays_allowed",
"f_property_type*d_luggage_dropoff_allowed",
"f_property_type*d_outdoor_shower",
"f_property_type*d_pool",
"f_property_type*d_private_pool",
"f_property_type*d_have_kitchen",
"f_property_type*d_have_stove",
"f_property_type*d_have_frige",
"f_property_type*d_coffee_machine",
"f_property_type*d_free_parking_on_street",
"f_property_type*d_have_cable",
"f_property_type*d_have_tv",
"f_property_type*d_have_sound_system",
"f_property_type*d_have_dryer",
"f_property_type*d_have_air_condfan",
"f_property_type*d_balcony",
"f_property_type*d_have_garden",
"f_property_type*d_have_breakfast",
"f_property_type*d_have_workoffice",
"f_property_type*d_instant_bookable",
"f_property_type*d_host_is_superhost",
"f_property_type*d_host_identity_verified")


```

```{r message=FALSE, warning=FALSE, include=FALSE}
#################################
# Create test and train samples #
#################################
# now all stuff runs on training vs test (holdout), alternative: 5-fold CV


# create test and train samples (80% of observations in train sample)
smp_size <- floor(0.8 * nrow(data))

## K = 5
k_folds <- 5
# Define seed value
seed_val <- 95

train_ids <- sample(seq_len(nrow(data)), size = smp_size)
data$train <- 0
data$train[train_ids] <- 1
# Create train and test sample variables
data_train <- data %>% filter(train == 1)
data_test <- data %>% filter(train == 0)

#Building the most complex model to use in LASSO
model4 <- paste0(" ~ ",paste(c(basic_lev, basic_add ,host,reviews, dummies, interactions),collapse = " + "))


# Creating the most complex OLS model to run a LASSO. Here LASSO is being used as a tool to choose predictors

# Set lasso tuning parameters:
# a) basic setup
train_control <- trainControl( method = "cv", number = k_folds)
# b) tell the actual lambda (penalty parameter) to use for lasso
tune_grid     <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))
# c) create a formula
formula <- formula(paste0("price ", paste(setdiff(model4, "price"), collapse = " + ")))

# Run LASSO
set.seed(seed_val)
lasso_model <- caret::train(formula,
                            data = data_train,
                            method = "glmnet",
                            preProcess = c("center", "scale"),
                            trControl = train_control,
                            tuneGrid = tune_grid,
                            na.action=na.exclude)
# Check the output
lasso_model
# Penalty parameters
lasso_model$bestTune
# Check th optimal lambda parameter
lasso_model$bestTune$lambda
# Check the RMSE curve
plot(lasso_model)

# One can get the coefficients as well
lasso_coeffs <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(coefficient = `s1`)  # the column has a name "1", to be renamed

lasso_coeffs
print(lasso_coeffs)

# Check the number of variables which actually has coefficients other than 0
lasso_coeffs_nz<-lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))

lasso_coeffs_nz

write_csv(lasso_coeffs_nz,"NonZeroCoefficients.csv")

# Get the RMSE of the Lasso model
#   Note you should compare this to the test RMSE
lasso_fitstats <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda)
lasso_fitstats

# Create an auxilary tibble
lasso_add <- tibble(Model='LASSO', Coefficients=nrow(lasso_coeffs_nz),
                    R_squared=lasso_fitstats$Rsquared, BIC = NA,
                    Training_RMSE = NA, Test_RMSE = lasso_fitstats$RMSE )


```

```{r message=FALSE, warning=FALSE, include=FALSE}

## Interaction
p1 <- price_diff_by_variables2(data, "f_property_type", "d_pool","Property Type", "Have pool") 
p2 <- price_diff_by_variables2(data, "f_property_type", "d_have_workoffice","Property Type", "Have work office")
p3 <- price_diff_by_variables2(data, "f_property_type", "d_have_breakfast","Property Type", "Have Breakfast")
p4 <- price_diff_by_variables2(data, "f_property_type", "d_free_parking_on_street","Property Type", "Have Free Parking") # <------------
p5 <- price_diff_by_variables2(data, "f_property_type", "d_have_garden","Property Type", "Have Garden")

p6 <- price_diff_by_variables2(data, "f_property_type", "d_have_sound_system","Property Type", "Have Sound Sysytem")

g_interactions <- plot_grid(p1, p2, p3,
                            p4, p5, p6, nrow=3, ncol=2)



```


```{r message=FALSE, warning=FALSE, include=FALSE}
# modifying the list of variables to be used based on LASSO results

dummies <- c("d_host_identity_verified","d_baking_sheet","d_beach_essentials","d_beachfront","d_bidet","d_board_games","d_cleaning_products",
            "d_cooking_basics","d_dining_table","d_dishes_and_silverware","d_drying_rack_for_clothing","d_elevator","d_fire_extinguisher",
            "d_first_aid_kit","d_hangers","d_hot_tub","d_hot_water","d_laundromat_nearby","d_lockbox","d_long_term_stays_allowed",
            "d_luggage_dropoff_allowed","d_mosquito_net","d_outlet_covers","d_pool","d_private_entrance","d_private_pool","d_roomdarkening_shades","d_safe","d_security_cameras_on_property",
            "d_toaster","d_wine_glasses","d_have_kitchen","d_have_frige", "d_coffee_machine","d_have_gril","d_free_parking_on_street","d_paid_parking_off_premises","d_wifi",
            "d_have_tv","d_shampoo_conditioner","d_have_body_soapgel","d_have_dryer","d_have_iron","d_have_air_condfan","d_have_garden","d_have_breakfast","d_family_friendly","d_have_fireplace",
            "d_has_availability")


interactions <- c("f_property_type*d_barbecue_utensils","f_property_type*d_bed_linens","f_property_type*d_bikes","f_property_type*d_cleaning_before_checkout",
                  "f_property_type*d_cooking_basics","f_property_type*d_essentials","f_property_type*d_ethernet_connection","f_property_type*d_extra_pillows_and_blankets",
                  "f_property_type*d_fire_pit","f_property_type*d_freezer","f_property_type*d_hangers","f_property_type*d_hot_tub", "f_property_type*d_hot_water",
                  "f_property_type*d_long_term_stays_allowed","f_property_type*d_luggage_dropoff_allowed","f_property_type*d_outdoor_shower","f_property_type*d_pool",
                  "f_property_type*d_pool","f_property_type*d_pool","f_property_type*d_private_pool","f_property_type*d_have_kitchen","f_property_type*d_have_stove",
                  "f_property_type*d_have_frige","f_property_type*d_free_parking_on_street","f_property_type*d_have_sound_system","f_property_type*d_have_air_condfan",
                  "f_property_type*d_have_air_condfan","f_property_type*d_have_garden","f_property_type*d_have_breakfast","f_property_type*d_have_workoffice",
                  "f_property_type*d_have_workoffice","f_property_type*d_instant_bookable","f_property_type*d_host_is_superhost", "f_property_type*d_host_is_superhost",
                  "f_property_type*d_host_identity_verified")

basic_lev  <- c("f_property_type", "n_accommodates", "n_beds", "flag_days_sincelast", "n_days_sincelast")


# Factorized variables
basic_add <- c("f_bathroom", "f_bedroom", "f_neighbourhood_group_cleansed", "n_availability_365")


reviews <- c("n_review_scores_rating", "flag_review_scores_rating","f_review_scores_rating",
             "n_number_of_reviews","f_number_of_reviews","flag_reviews_per_month","n_reviews_per_month")


host <- c("d_host_is_superhost", "d_host_identity_verified")

# Building OLS models

model1 <- " ~ n_accommodates"
model2 <- paste0(" ~ ",paste(basic_lev,collapse = " + "))
model3 <- paste0(" ~ ",paste(c(basic_lev, basic_add, host,reviews, dummies ),collapse = " + "))

m1 <-  "~ n_accommodates"
m2 <- "~ n_accommodates+ basic_lev"
m3 <- "~ n_accommodates+ basic_lev + basic_add + reviews + host + dummies"
m4<- "~ n_accommodates+ basic_lev + basic_add + reviews + host + dummies + interaction"

  
  
model_variables <- c( m1,m2,m3,m4)
model_names <- c("M1", "M2", "M3","M4")
model_table <- as.data.frame(cbind(model_names, model_variables))
model_headings <- c("Model", "Predictor Variables")
colnames(model_table) <- model_headings


# Do the iteration

library(fixest)
for ( i in 1:4 ){
  print(paste0( "Estimating model: " ,i ))
  # Get the model name
  model_name <-  paste0("model",i)
  model_pretty_name <- paste0("M",i,"")
  # Specify the formula
  yvar <- "price"
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  
  # Estimate model on the whole sample
  model_work_data <- feols( formula , data = data_train , vcov='hetero' )
  #  and get the summary statistics
  fs  <- fitstat(model_work_data,c('rmse','r2','bic'))
  BIC <- fs$bic
  r2  <- fs$r2
  rmse_train <- fs$rmse
  ncoeff <- length( model_work_data$coefficients )
  
  # Do the k-fold estimation
  set.seed(seed_val)
  cv_i <- train( formula, data_train, method = "lm",
                 trControl = trainControl(method = "cv", number = k_folds))
  rmse_test <- mean( cv_i$resample$RMSE )
  
  # Save the results
  model_add <- tibble(Model=model_pretty_name, Coefficients=ncoeff,
                      R_squared=r2, BIC = BIC,
                      Training_RMSE = rmse_train, Test_RMSE = rmse_test )
  if ( i == 1 ){
    model_results <- model_add
  } else{
    model_results <- rbind( model_results , model_add )
  }
}

# Check summary table
# Add it to final results

model_results <- rbind( model_results , lasso_add )
model_results

## As per these results, model4 is clearly over fitted as the R-squared comes out to be highest BIC.##
## The purpose of model4 was primarily to include all the relevant variables and use it in LASSO to identify predictors with non-zero coefficients.##



#testing model 3

predictors_model3 <- c(basic_lev, basic_add, dummies, host , reviews)
set.seed(95)
system.time({
  ols_model <- train(
    formula(paste0("price ~", paste0(predictors_model3, collapse = " + "))),
    data = data_train,
    method = "lm",
    trControl = train_control
  )
})
ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))

ols_model_coeffs_df


```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Random Forest ##

predictors <- c(basic_lev,basic_add, host, reviews, dummies,interactions)

# set tuning 
tune_grid <- expand.grid(
  .mtry = c(8, 10, 12),
  .splitrule = "variance",
  .min.node.size = c(5, 10, 15)
)

set.seed(1995)
system.time({
  rf_model <- train(
    formula(paste0("price ~", paste0(predictors, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity"
  )
})
rf_model

rf_tuning_model_table <- rf_model$results %>%
  dplyr::select(mtry, min.node.size, RMSE) %>%
  dplyr::rename(nodes = min.node.size) %>%
  spread(key = mtry, value = RMSE)

rf_tuning_model_table

# auto tuning first - gives 80 predictors
set.seed(95)
system.time({
  rf_model_auto <- train(
    formula(paste0("price ~", paste0(predictors, collapse = " + "))),
    data = data_train,
    method = "ranger",
    trControl = train_control,
    importance = "impurity"
  )
})

```


```{r message=FALSE, warning=FALSE, include=FALSE}
##Variable Importance Plots rf_model
rf_model_var_imp <- ranger::importance(rf_model$finalModel)/1000

rf_model_var_imp_df <-
  data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_group_cleansed", "Neighbourhood", varname) ) %>%
  mutate(varname = gsub("f_property_type", "Property type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_var_imp_df

# to have a quick look
plot(varImp(rf_model))

# have a version with top 10 vars only
ggplot(rf_model_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()

##############################
# 2) varimp plot grouped
##############################

# grouped variable importance - keep binaries created off factors together
varnames <- rf_model$finalModel$xNames

f_neighbourhood_group_cleansed_varnames <- grep("f_neighbourhood_group_cleansed",varnames, value = TRUE)

f_host_varnames <- grep("d_host",varnames, value = TRUE)

f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)

f_reviews_varnames <- grep("review",varnames, value = TRUE)


#dummies_varnames?
t <-  grep("d_",varnames, value = TRUE)
dummies_varnames <-  t[6:159]
  
# c("d_host_identity_verified","d_baking_sheet","d_beach_essentials","d_beachfront","d_bidet","d_board_games","d_cleaning_products",
  #                     "d_cooking_basics","d_dining_table","d_dishes_and_silverware","d_drying_rack_for_clothing","d_elevator","d_fire_extinguisher",
  #                     "d_first_aid_kit","d_hangers","d_hot_tub","d_hot_water","d_laundromat_nearby","d_lockbox","d_long_term_stays_allowed",
  #                     "d_luggage_dropoff_allowed","d_mosquito_net","d_outlet_covers","d_pool","d_private_entrance","d_private_pool","d_roomdarkening_shades","d_safe","d_security_cameras_on_property",
  #                     "d_toaster","d_wine_glasses","d_have_kitchen","d_have_frige", "d_coffee_machine","d_have_gril","d_free_parking_on_street","d_paid_parking_off_premises","d_wifi",
  #                     "d_have_tv","d_shampoo_conditioner","d_have_body_soapgel","d_have_dryer","d_have_iron","d_have_air_condfan","d_have_garden","d_have_breakfast","d_family_friendly","d_have_fireplace",
  #                     "d_has_availability")

groups <- list(host =f_host_varnames,
               property_type = f_property_type_varnames,
               reviews = f_reviews_varnames,
               neighbourhood= f_neighbourhood_group_cleansed_varnames,
               Amenities = dummies_varnames,
               bathroom = "f_bathroom",
               last_review = "n_days_sincelast",
               n_accommodates = "n_accommodates",
               availability_365="n_availability_365",
               n_beds = "n_beds")

# Need a function to calculate grouped var-imp

group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(ranger::importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}

rf_model_var_imp_grouped <- group.importance(rf_model$finalModel, groups)
rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
                                          imp = rf_model_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

ggplot(rf_model_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()

##Variable Importance Plots rf_model_auto

rf_model_auto_var_imp <- ranger::importance(rf_model_auto$finalModel)/1000
rf_model_auto_var_imp_df <-
  data.frame(varname = names(rf_model_auto_var_imp),imp = rf_model_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_group_cleansed", "Neighbourhood:", varname) ) %>%
  mutate(varname = gsub("f_property_type", "Property type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))
rf_model_auto_var_imp_df

# to have a quick look

plot(varImp(rf_model_auto))

# have a version with top 10 vars only

pp <- ggplot(rf_model_auto_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.75) +
  ylab("Importance (Percent)") +
  xlab("Variable Name") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()


##############################
# 2) varimp plot grouped

##############################
# grouped variable importance - keep binaries created off factors together

varnames_auto <- rf_model_auto$finalModel$xNames

f_neighbourhood_group_cleansed_varnames_auto <- grep("f_neighbourhood_group_cleansed",varnames, value = TRUE)
f_host_varnames_auto <- grep("d_host",varnames_auto, value = TRUE)
f_property_type_varnames_auto <- grep("f_property_type",varnames_auto, value = TRUE)
f_reviews_varnames_auto <- grep("review",varnames_auto, value = TRUE)
dummies_varnames_auto <- t[6:159]


groups_auto <- list(host=f_host_varnames_auto,
                    property_type = f_property_type_varnames_auto,
                    reviews = f_reviews_varnames_auto,
                    neighbourhood=f_neighbourhood_group_cleansed_varnames_auto,
                    Ammenities = dummies_varnames_auto,
                    bathroom = "f_bathrooms",
                    last_review = "n_days_sincelast",
                    n_accommodates = "n_accommodates",
                    availability_365="n_availability_365",
                    n_beds = "n_beds")


# Need a function to calculate grouped var-imp

group.importance <- function(rf.obj, groups_auto) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(ranger::importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}

rf_model_auto_var_imp_grouped <- group.importance(rf_model_auto$finalModel, groups)
rf_model_auto_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_auto_var_imp_grouped),
                                               imp = rf_model_auto_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

pp1 <- ggplot(rf_model_auto_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color='red', size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color='red', size=0.7) +
  ylab("Importance (Percent)") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()



# evaluate random forests

results <- resamples(
  list(
    model_1  = rf_model,
    model_auto  = rf_model_auto
  )
)
summary(results)


```

```{r message=FALSE, warning=FALSE, include=FALSE}
# CART with pruning

# CART with built-in pruning

set.seed(110)
system.time({
  cart_model <- train(
    formula(paste0("price ~", paste0(predictors, collapse = " + "))),
    data = data_train,
    method = "rpart",
    tuneLength = 10,
    trControl = train_control
  )
})

cart_model

# Tree graph

rpart.plot(cart_model$finalModel, tweak=1.2, digits=-1, extra=1)


```

```{r message=FALSE, warning=FALSE, include=FALSE}
# GBM

gbm_grid <-  expand.grid(interaction.depth = 5, # complexity of the tree
                         n.trees = 250, # number of iterations, i.e. trees
                         shrinkage = 0.1, # learning rate: how quickly the algorithm adapts
                         n.minobsinnode = 20 # the minimum number of training set samples in a node to commence splitting
)

set.seed(111)
system.time({
  gbm_model <- train(formula(paste0("price ~", paste0(predictors, collapse = " + "))),
                     data = data_train,
                     method = "gbm",
                     trControl = train_control,
                     verbose = FALSE,
                     tuneGrid = gbm_grid)
})
gbm_model
gbm_model$finalModel
# save( gbm_model , file = 'gbm_model.RData' )

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# get prediction rmse and add to next summary table
# ---- compare these models

final_models <-
  list("OLS" = ols_model,
       "CART" = cart_model,
       "Random forest 1: Tuning provided" = rf_model,
       "Random forest 2: Auto Tuning" = rf_model_auto,
       "GBM"  = gbm_model)
results <- resamples(final_models) %>% summary()
results

# Model selection is carried out on this CV RMSE
result <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")
result

```


```{r message=FALSE, warning=FALSE, include=FALSE}
#########################################################################################
# Partial Dependence Plots for the best model; random forest with auto tuning parameters
#########################################################################################
# 1) Property Type
pdp_f_property_type <- pdp::partial(rf_model_auto, pred.var = "f_property_type", 
                                    pred.grid = distinct_(data_test, "f_property_type"), 
                                    train = data_train)
property_pdp <- pdp_f_property_type %>%
  autoplot( ) +
  geom_point(color='red', size=2) +
  geom_line(color='red', size=1) +
  ylab("Predicted price") +
  xlab("Property Type") +
  theme_bw()

# 2) Number of accommodates
pdp_n_accommodates <- pdp::partial(rf_model_auto, pred.var = "n_accommodates", 
                                   pred.grid = distinct_(data_test, "n_accommodates"), 
                                   train = data_train)
pdp_n_accommodates %>%
  autoplot( ) +
  geom_point(color='red', size=4) +
  ylab("Predicted price") +
  xlab("Accommodates (persons)") +
  scale_y_continuous(limits=c(80,120), breaks=seq(80,120, by=10)) +
  theme_bw()

# 3) neighborhood

pdp_f_neighbourhood_group_cleansed <- pdp::partial(rf_model_auto, pred.var = "f_neighbourhood_group_cleansed", 
                                   pred.grid = distinct_(data_test, "f_neighbourhood_group_cleansed"), 
                                   train = data_train)

n_pdp <- pdp_f_neighbourhood_group_cleansed %>%
  autoplot( ) +
  geom_point(color='red', size=4) +
  ylab("Predicted price") +
  xlab("Nieghbourhoods") +
  theme_bw()

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Sub-sample performance: RMSE / mean(y) ---------------------------------------
# NOTE  we do this on the holdout set.
# 

data_holdout_w_prediction <- data_test %>%
  mutate(predicted_price = predict(rf_model_auto, newdata = data_test))

######### create nice summary table of heterogeneity

a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(n_accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )



b <- data_holdout_w_prediction %>%
  filter(n_beds %in% c("2","3", "4","5","6","7")) %>%
  group_by(n_beds) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )

c <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )


d <- data_holdout_w_prediction %>%
  filter(f_property_type %in% c("apartment", "condo","loft")) %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )

## Save output ##

colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
c<- cbind("All", c)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")

line1 <- c("Apartment size", "", "", "")
line2 <- c("Beds", "", "", "")
line3 <- c("Property Type", "", "", "")

result_3 <- rbind(line1,a,line2, b,line3,d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))
result_3


```

```{r message=FALSE, warning=FALSE, include=FALSE}
# FIGURES FOR FITTED VS ACTUAL OUTCOME VARIABLES #
##--------------------------------------------------

Ylev <- data_test[["price"]]

# Predicted values
prediction_test_pred <- as.data.frame(predict(rf_model_auto, newdata = data_test, interval="predict"))

predictionlev_test <- cbind(data_test[,c("price","n_accommodates")],
                               prediction_test_pred)



# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_test[,3] )
# Check the differences
d$elev <- d$ylev - d$predlev

# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev), color = "purple", size = 1,
             shape = 16, alpha = 0.5, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 275, yend =275), size=0.8, color="black", linetype=2) +
  labs(y = "Price (US dollars)", x = "Predicted price  (US dollars)") +
  theme_bg()
level_vs_pred
```



## Executive summary: 

In this project I am tasked to help a company which is operating small and mid-size apartments hosting 2-6 guests to set the on optimum rental price for its apartments in the city of **Puglia** in Italy. To achieve this I will build a price prediction model based on data provided by [Inside Airbnb](http://insideairbnb.com/get-the-data.html) which was scraped between December 30, 2021 and December 31, 2021. The prediction was built on several features of the accommodation such as the number of bedrooms, bathrooms, the number of guests it accommodates as well as on information about the host, including the scores of ratings given to apartment. Moreover, on several variables aimed at describing different kinds of amenities offered by the apartment already in the city. I analyzed 4 different kinds of models, to find the best prediction, namely OLS, CART, Random forest and GBM. Out of these the I chose the prediction results of random forest model to be the best one.  To see all the codes and files I created for this project please visit my [Github](https://github.com/shahaligardezi/DA3/tree/main/Assignment2)


## Data Cleaning 

The data for the chosen destination was a large dataset with more than 33000 observations and 74 variables. This data required intense cleaning before I could begin our analysis. I performed basic cleaning that involved filtering the property type to the ones of our interest that are apartments so I selected all observation of Entire apt, Entire serviced apartments, Entire Loft and Entire Condominium, and then I filtered the number of guests to 2 to 6. The main part of the cleaning process rested on cleaning the amenities. In our dataset all the amenities were written together in one large vector with total of 1442 unique amenities. Since I am interested in analyzing the effect of each amenity on the target variable I needed to create meaningful dummy variable out of the names of amenities.  I separated each amenity from the list, grouped them together if they were similar (Wifi & Internet, TV and cable) and chose only those which had at least 1% of measurable observations. In this way I was able to narrow down the amenities to 85. 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=8}
annotate_figure(price_hist_grid,bottom =
                  text_grob("Note: Apartments with 2-6 accommodation capacity. Histogram without extreme values (price < 500 Euros)"))

```



In order to deal with the missing values, I initially dropped those variables that had more than 50% of the missing values and using domain knowledge, I dropped those variables as well which will play no role in our analysis for example picture, url, name, host response rate etc. For the rest I applied imputation. Some of the main variables like number of bathrooms, bedrooms and beds had less than 1% of missing values, for these variables I used logical assumptions while imputing values. For instance, for bathrooms I imputed the median value in place of missing values. For bedrooms I assumed 2 people can share one room thus I imputed the value of reminder of the division by 2. For number of beds I assumed that for 3 people atleast 2 beds are needed. I didn’t not create a flag variable as the number of missing values are less, however for variables with more than 30% missing values I created a flag variable with a value of 1 and imputed median value. In this way our dataset was left with no missing values.

During the cleaning of the target variable, price, I dropped all the observations where price was not available as we should impute in our target variable. Since the analysis focused on small to medium size of apartments, I dropped the price above 500 Euros which were less than less than 1% of observations considering them as extreme values. Then the distribution of the price was checked which was found to be bit right skewed due to the presence of high values such as 500 Euros. I decided to proceed with price variable without the log transformation for this analysis. While it is true that that log will bring us closer to normal distribution of the variable, but it will also lead to errors when transformed back to normal prices.


## Variables and feature engineering

After data cleaning the variables we are left with are broadly divided as the following.

*Numeric variables:* These variables define size for example, number of beds, number of accommodates, number of bathrooms and bedrooms, the minimum number of nights required to rent the place and the availability of the apartment in 365 days of the year. 
*Factor variables:* These are categorical variables that are either in string or numeric form. For example, the neighborhood the apartment is in or the type of property (apartment, condominium or loft).
*Dummy variables:* These are binary variables mostly describing the amenities offered in the property such the Wifi, pool, beachfront facing property, kitchen supplies, elevator etc.
*Review variables:* These describe the reviews and ratings characteristics for an individual property. Number of reviews, the rating for those reviews and the mean monthly reviews received. 
*Host variables:* These variables describe the characteristics of the host of the property. They are binary variables like host is a super-host or if the host is verified

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.width=8}
g_interactions
```


After the variables are set, we need to find the interaction terms between property type and amenities to include in our prediction models. In order to evaluate which interactions terms to use, I logically selected those amenities for our analysis which have an effect on the price. I used the helper functions provided by Bekes & Kézdi to help me plot the histogram which help me with the logical selection. The amenities whose inclusion showed more than 10 Euros of difference on price were included in our model. In this way I was left with 40 important amenities. 

The next step was to perform LASSO using all the variables (that is most complex model). The approach that I have used in this analysis is to use LASSO as a variable selection method and use the non-zero predictors given out by the LASSO for all of the subsequent prediction models (OLS, Random Forest, CART and GBM). After running LASSO we are left with 102 predictors which we shall be using for the price prediction models.


## Cross validation & Holdout

To improve model performance, I created work set (train and test) sample and the holdout set from the dataset. The value of k was set at 5 which ensured 80% of the 2100 observations for training and 20% for test. The models that I will build later are each trained through 5-fold cross-validation so as to render the least overfitting coefficients, taking the average of each model's 5 test folds, warranting the RMSE and BIC statistics with no assumptions. 

## OLS Predictive Model
```{r echo=FALSE, message=FALSE, warning=FALSE,fig.width=8}
model_table %>%
  kbl(caption = "<center><strong>Versions of the Airbnb Apartment Price Prediction Models</strong></center>", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling( position = "center")
```

I built 4 Models to run my OLS prediction on using different number of predictors that I got from the LASSO. The first model had only one predictor, the n_accommodates variable, model 2 had 5 predictors, model 3 had 67 and model had 102 variables respectively. Model 4 was the overfitted model with all the variables. According to my OLS regression results, model 3 proved to be the best predictive model out of these 4. As can be seen below. Even though we see a higher BIC value in model 3 than in model 2, model 3 has the lowest RMSE in the test set. When BIC and Cross validation produce conflicting results, we should prefer to side with the cross-validation results since it’s not based on auxiliary assumptions (BEKES, 2021). 

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.width=8}
model_results %>% kbl(caption = "Comparing Model Fit Model Measures", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling( position = "center")
```


## Random Forest
Random Forest is the machine learning predictive algorithm that uses the results of many regression trees. The algorithm creates large number of trees and averages the prediction of them to achieve one average. In this way better prediction is created as opposed to a single model. In our case we used the same holdout and work set and run our model with tuning parameter to allow cross validation to find the tuning parameter value with lowest RMSE value.  


The tuning parameter choice is kept same as did in the case by Bekes and Kézdi. Used 3-by-3 for defining mtry tuning parameter and minimum number of observations in each tree split. For our number of variable (mtry) we took 8, 10 , 12 and for the (min. nodes) in terminal nodes we have taken (5,10,15). The result from the cross validated test set RMSE values on the combination is shown below. Based on this regression the lowest RMSE value was 56.2 at the minimum node of 5 and mtry of 12 as shown below.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.width=8}
rf_tuning_model_table%>% kbl(caption = "Random Forest RMSE by tuning parameters", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling(full_width = F)
```

Further I can an auto tune version of random forest allowing algothrim to pick up the tuning parameter itself. The cross-validated RMSE for autotune produced slightly better results with cross-validated RMSE of 57.1 at 5 terminal nodes and mtry of 89 variables. 

## CART & GBM
I further tested the CART model with pruning to see how my prediction works based on the Test RMSE value. The lowest test RMSE was 62.8, highest so far. This is understandable as the CART created a single tree which tends to overfit the data despite pruning. Running GBM got us close to the lowest Test RMSE (GBM RMSE = 57.2) but autotuned Random Forest is still the winner. 


## Variable Importance
Variable importance is a helpful diagnostic tool that helps us gain useful insight about how much each variable contributes towards predicting our target variable. The results of variable importance, from both self-tuned and auto-tuned Random Forest were mostly same. The following top 10 important variable plot shows variables which ones had the largest MSE reduction in auto tuned model. It shows that number of days of availability is the most important x predictor with more than 6% importance. In second chart these variables are grouped based on their factor groups, it turns out that amenities account for more than 50% of importance. 
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=8 , fig.height=3}
fig110 <- ggarrange(pp,pp1, nrow=1)
fig110
```



## Partial Dependence Plot (PDP)
We now employ another diagnostic tool, the partial dependence plot (PDP) to evaluate how our predicted y (price) differs for different values of x when all other x values are the same. I decided to take property type, number of accommodates and grouped neighborhoods as my x predictors.  The graphs for each are shown below. A graph for property type shows that entire apartments have the highest average predicted price. In the second graph we see that as the number of accommodates increases, the average prices tend to increase linearly. Third graph shows how average prices vary in different neighborhoods while other predictors are held the same.
```{r echo=FALSE, fig.height=3, fig.width=8, message=FALSE, warning=FALSE}
fig111 <- ggarrange(property_pdp,n_pdp,nrow=1)
fig111
```


## Sub sample 
To further check the performance of our RF model, I ran sub sample on four predictor variables (number of accommodates, number of beds, property type and neighbourhoods) as shown in the table below. For both apartment size, the prediction error is fairly balanced with regards to the size, however it is harder to predict the prices of large apartments. For number of beds, our prediction predicts the price of 6 beds with the lowest prediction error followed by 2 and 3 beds as the number of observations are high but for others we need to collect more data. Similarly, in sub sample test of neighborhood we see that our model predicts the prices of Barletta-Andria-Trani neighborhood with lowest prediction error, followed by Brinidisi which PDP suggest. This is a deviation with PD plot can be accredited to the limitation in data and small number of observations for Barletta-Andria-Trani. Drilling down into the property type, the sub sample supports the result of PD plot. The home/apartment has the lowest prediction error.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.width=8}
result_3%>% kbl(caption = "Performance across sub-sample", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling( position = "center")
```


## Conclusion

After conducting this analysis, according to the results my best model was the Random Forest model with auto tuning as that gave the lowest cross validated RMSE value. While there were different data preparation steps that had to performed in our data than compared to the 2017 case study on Airbnb in London by Bekes and Kezidi, (owing to the difference in data) the final predictive pricing model was in coherence. The lowest CV RMSE value for Puglia comes out to be 56.2 and while that of London is 44.5 we also need to consider other factors such as inflation rate, country’s GDP and tourism in these cities they have an effect on the data and prices.  This model predicts the prices of the home/apartment, accommodating at-most 3 guests, in Brindisi neighborhood with lowest prediction error. This model can be applied for predicting prices of apartments with these specifications on live dataset provided there is an high external validity of that dataset with this data. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
result %>% kbl(caption = "Horse Race of Models CV RSME", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  kable_styling( position = "center")
```


## Credits:

Codes used by Professor Bekes (Central European University) and Professor Kézdi the author of DATA ANALYSIS FOR BUSINESS, ECONOMICS, AND POLICY. [CAMBRIDGE UNIV PRESS. proved to be the basis for this analysis. They provided the inspiration for starting and completion of the project.

